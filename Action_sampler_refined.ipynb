{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from utils import init                                   # import it from utils.py or uncomment the (def init()-- function)\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(module, weight_init, bias_init, gain =1):                 # can be imported from utils.py\n",
    "    weight_init(module.weight.data, gain = gain)\n",
    "    if hasattr(module, 'bias') and module.bias is not None:\n",
    "        bias_init(module.bias.data)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Categorical(Categorical):\n",
    "    def __init__(self, _logits):\n",
    "        super().__init__(logits = _logits)\n",
    "        self._logits = self.logits\n",
    "        self.weighted_sampler = WeightedRandomSampler\n",
    "\n",
    "    def gumbel_softmax_sample(self, tau, device):\n",
    "        dist = F.gumbel_softmax(self._logits, tau = tau, hard = False)\n",
    "        action = torch.multinomial(dist, num_samples = 1).to(device)\n",
    "        # action = torch.tensor(list(self.weighted_sampler(dist, 1, replacement = False))).to(device)\n",
    "        return action.squeeze(-1)\n",
    "    \n",
    "    def mode(self):\n",
    "        return torch.argmax(self._logits, dim = -1, keepdim = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  MultiHeadCategorical(nn.Module):\n",
    "    def __init__(self, num_inputs, action_dim, action_num, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        init_ =  lambda m: init(m,\n",
    "                               nn.init.orthogonal_,\n",
    "                               lambda x: nn.init.constant_(x, 0),\n",
    "                               gain = 0.01) \n",
    "        self.action_num = action_num\n",
    "        self.linear_list = torch.nn.ModuleList([init_(nn.Linear(num_inputs, action_dim).to(device)) for _ in range (action_num)])    # could be only for training, for backpropagation (differtiable training) \n",
    "        self.logits_head = []\n",
    "        self.weight_sample = WeightedRandomSampler\n",
    "        self.device = device\n",
    "        self.categorical_list = []\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.categorical_list = [_Categorical(linear(inputs)) for linear in self.linear_list]    # sample has not been done yet, # probabillity distributions, enables sampling\n",
    "\n",
    "    def gumbel_softmax_sample(self, tau):                      \n",
    "        action = torch.cat([p.gumbel_softmax_sample(tau, self.device) for p in self.categorical_list]) \n",
    "        self.action = torch.cat([p.gumbel_softmax_sample(tau, self.device) for p in self.categorical_list])  # y = softmax((logits + gumbel_noise) / tau)\n",
    "        return action\n",
    "    \n",
    "    def probs(self):\n",
    "        if self.action_num == 1:\n",
    "            return self.categorical_list[0].probs\n",
    "        else:\n",
    "            return torch.cat([p.probs.unsqueeze(-1) for p in self.categorical_list], dim = -1)  #unsqueeze(-1)- add new dimension at the last position\n",
    "            \n",
    "\n",
    "    def log_probs(self, action):\n",
    "        if self.action_num == 1:\n",
    "            return self.categorical_list[0].log_probs(action)\n",
    "        else:\n",
    "            return torch.cat([p.log_prob(a).unsqueeze(-1) for a, p in zip(action, self.categorical_list)], dim = -1)\n",
    "        \n",
    "    def mode(self):\n",
    "        if self.action_num == 1:\n",
    "            return self.catelogical_list[0].mode()\n",
    "        else:\n",
    "            return torch.cat([p.mode() for p in self.categorical_list])\n",
    "        \n",
    "    def sample(self):                                         # true discrete sample, during evaluation and interence\n",
    "        if self.action_num == 1:\n",
    "            return self.categorical_list[0].sample()\n",
    "        else:\n",
    "            return torch.cat([p.sample() for p in self.categorical_list])\n",
    "        \n",
    "    def entropy(self):\n",
    "        if self.action_num == 1:\n",
    "            return self.categorical[0].entropy()\n",
    "        else:\n",
    "            return torch.cat([p.entropy() for p in self.categorical_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_Categorical(logits: torch.Size([1, 3])), _Categorical(logits: torch.Size([1, 3])), _Categorical(logits: torch.Size([1, 3])), _Categorical(logits: torch.Size([1, 3]))]\n",
      "4\n",
      "actions: tensor([0, 2, 1, 0])\n",
      "probabilities: tensor([[[0.3314, 0.3324, 0.3295, 0.3357],\n",
      "         [0.3295, 0.3362, 0.3344, 0.3309],\n",
      "         [0.3391, 0.3314, 0.3361, 0.3334]]], grad_fn=<CatBackward0>)\n",
      "mode: tensor([2, 1, 2, 0])\n",
      "sample: tensor([1, 0, 1, 0])\n",
      "entropy: tensor([1.0985, 1.0986, 1.0986, 1.0986], grad_fn=<CatBackward0>)\n",
      "log-probs; tensor([[-1.1045, -1.1043, -1.0953, -1.0915]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 16\n",
    "action_dim = 3\n",
    "action_num = 4\n",
    "tau = 0.85\n",
    "\n",
    "model = MultiHeadCategorical(num_inputs, action_dim, action_num, device)\n",
    "\n",
    "inputs = torch.randn(1, num_inputs).to(device)\n",
    "inputs.shape\n",
    "\n",
    "model.forward(inputs)\n",
    "print(model.categorical_list)                # logits, raw output from linear layers\n",
    "print(len(model.categorical_list))\n",
    "\n",
    "model.gumbel_softmax_sample(tau)\n",
    "actions = model.action                           # action sampled for each agent\n",
    "print(\"actions:\", actions)\n",
    "\n",
    "print(\"probabilities:\", model.probs())\n",
    "print(\"mode:\", model.mode())\n",
    "print(\"sample:\", model.sample())\n",
    "print(\"entropy:\", model.entropy())\n",
    "\n",
    "print(\"log-probs;\", model.log_probs(actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
